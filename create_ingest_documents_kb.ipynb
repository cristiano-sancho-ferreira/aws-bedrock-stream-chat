{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Bases for Amazon Bedrock - Exemplo de ponta a ponta\n",
    "\n",
    "Este notebook fornece código de exemplo para construir um índice vazio do OpenSearch Serverless (OSS), uma Knowledge Base do Amazon Bedrock e ingerir documentos no índice.\n",
    "\n",
    "Um pipeline de dados que ingere documentos (normalmente armazenados no Amazon S3) em uma base de conhecimento, ou seja, um banco de dados vetorial como o OpenSearch Service Serverless (OSS), para que esteja disponível para pesquisa quando uma pergunta for recebida.\n",
    "\n",
    "#### Etapas:\n",
    "- Criar uma execution role do Amazon Bedrock Knowledge Base com as políticas necessárias para acessar dados do S3 e gravar embeddings no OSS.\n",
    "- Criar um índice vazio do OpenSearch serverless.\n",
    "- Baixar documentos.\n",
    "- Criar uma Knowledge Base do Amazon Bedrock.\n",
    "- Criar uma fonte de dados dentro da Knowledge Base que se conectará ao Amazon S3.\n",
    "- Iniciar um trabalho de ingestão usando as APIs do Knowledge Bases (KB) que lerão dados do S3, dividirão em chunks, converterão os chunks em embeddings usando o modelo Amazon Titan Embeddings e armazenarão esses embeddings no OSS. Tudo isso sem precisar construir, implantar e gerenciar o pipeline de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso de uso\n",
    "### Conjunto de dados\n",
    "Neste exemplo, você usará vários anos das Cartas aos Acionistas da Amazon como um corpus de texto para realizar perguntas e respostas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "Antes de executar o restante deste notebook, você precisará executar as células abaixo para garantir que as bibliotecas necessárias estejam instaladas e também se conectar ao Amazon Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -U opensearch-py==2.3.1\n",
    "%pip install -U boto3==1.33.2\n",
    "%pip install -U retrying==1.3.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import boto3\n",
    "import pprint\n",
    "import time\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from utility import create_bedrock_execution_role, create_oss_policy_attach_bedrock_execution_role, create_policies_in_oss\n",
    "import random\n",
    "from retrying import retry\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "suffix = random.randrange(200, 900)\n",
    "\n",
    "boto3_session = boto3.session.Session()\n",
    "region_name = boto3_session.region_name\n",
    "bedrock_client = boto3_session.client(\"bedrock-runtime\", region_name=region_name)\n",
    "bedrock_agent_client = boto3_session.client(\"bedrock-agent\", region_name=region_name)\n",
    "aoss_client = boto3_session.client(\"opensearchserverless\")\n",
    "s3_client = boto3_session.client(\"s3\")\n",
    "\n",
    "bucket_name = \"cdbes01e08-sancho\" #troque o nome deste bucket por um bucket seu!\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definindo a pergunta que faremos ao modelo\n",
    "query = \"What is Amazon's doing in the field of generative AI?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definindo o modelo que será utilizando neste notebook\n",
    "model_id = \"anthropic.claude-v2\" # para claude v2, utilize \"anthropic.claude-v2 or claude-instant-v1\"\n",
    "model_arn = f\"arn:aws:bedrock:us-east-1::foundation-model/{model_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' Amazon has made some notable investments and developments related to '\n",
      " 'generative AI:\\n'\n",
      " '\\n'\n",
      " '- AWS OpenAI Service - In 2021, Amazon announced a new fully managed AWS '\n",
      " 'service that allows access to OpenAI models like GPT-3 for text generation. '\n",
      " 'This makes advanced generative AI more accessible to developers.\\n'\n",
      " '\\n'\n",
      " '- Alexa Conversations - The Alexa virtual assistant uses some generative '\n",
      " 'techniques to have more natural conversations. The Alexa Skills Kit enables '\n",
      " 'developers to build conversational Alexa skills.\\n'\n",
      " '\\n'\n",
      " '- Amazon Kendra - This is a natural language search service that uses AI to '\n",
      " 'understand user queries and find answers in documents. It generates natural '\n",
      " 'language responses. \\n'\n",
      " '\\n'\n",
      " '- Amazon CodeWhisperer - Announced in 2022, this is a code generation '\n",
      " 'service to help developers by generating code based on simple natural '\n",
      " 'language prompts. It uses GPT-3 and other techniques under the hood.\\n'\n",
      " '\\n'\n",
      " '- Amazon has research scientists working on internal generative AI and '\n",
      " 'machine learning projects, like sequence-to-sequence models for text '\n",
      " 'generation. However, many of the details remain unpublished.\\n'\n",
      " '\\n'\n",
      " '- There are also reports that Amazon may be developing a ChatGPT rival, '\n",
      " 'though the details are still unknown. Amazon has the data, cloud '\n",
      " 'infrastructure, and AI talent to compete in this space.\\n'\n",
      " '\\n'\n",
      " 'So in summary, Amazon has products and services in deploying generative AI, '\n",
      " 'but is also actively researching and developing new generative AI techniques '\n",
      " 'internally. The area seems to be a priority for Amazon going forward.')\n"
     ]
    }
   ],
   "source": [
    "# Fazendo a pergunta antes de criar a base de conhecimento e sem utilizar RAG\n",
    "key_word_args = {\n",
    "  \"modelId\": model_id,\n",
    "  \"body\": \"{\\\"prompt\\\":\\\"Human: \" + query + \"\\\\nAssistant:\\\",\\\"max_tokens_to_sample\\\":300,\\\"temperature\\\":1,\\\"top_k\\\":250,\\\"top_p\\\":0.999,\\\"stop_sequences\\\":[\\\"\\\\n\\\\nHuman:\\\"],\\\"anthropic_version\\\":\\\"bedrock-2023-05-31\\\"}\"\n",
    "}\n",
    "\n",
    "response = bedrock_client.invoke_model(**key_word_args)\n",
    "response_body = json.loads(response.get(\"body\").read())\n",
    "generated_text = response_body.get(\"completion\")\n",
    "\n",
    "pp.pprint(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar um repositório de vetores - índice no Amazon OpenSearch Serverless\n",
    "\n",
    "### Passo 1 - Criar role de execução do Bedrock NB, poíticas e coleção no OSS\n",
    "Primeiro de tudo, temos que criar um repositório de vetores. Nesta seção, vamos usar *Amazon OpenSearch Serverless.*\n",
    "\n",
    "O Amazon OpenSearch Serverless é uma opção serverless do Amazon OpenSearch Service. Como desenvolvedor, você pode usar o OpenSearch Serverless para executar cargas de trabalho de petabytes sem precisar configurar, gerenciar e dimensionar clusters do OpenSearch. Você obtém os mesmos tempos de resposta interativos de milissegundos do OpenSearch Service com a simplicidade de um ambiente serverless. Pague apenas pelo que usar, escalando recursos automaticamente para fornecer a capacidade certa para sua aplicação, sem impactar a ingestão de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bedrock_kb_execution_role = create_bedrock_execution_role(bucket_name=bucket_name)\n",
    "bedrock_kb_execution_role_arn = bedrock_kb_execution_role[\"Role\"][\"Arn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cria as políticas de segurança, rede e acesso a dados\n",
    "vector_store_name = f\"bedrock-sample-rag-{suffix}\"\n",
    "encryption_policy, network_policy, access_policy = create_policies_in_oss(\n",
    "    vector_store_name=vector_store_name,\n",
    "    aoss_client=aoss_client,\n",
    "    bedrock_kb_execution_role_arn=bedrock_kb_execution_role_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cria a coleção no OpenSearch Serverless\n",
    "collection = aoss_client.create_collection(name=vector_store_name,type=\"VECTORSEARCH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'ResponseMetadata': { 'HTTPHeaders': { 'connection': 'keep-alive',\n",
      "                                         'content-length': '314',\n",
      "                                         'content-type': 'application/x-amz-json-1.0',\n",
      "                                         'date': 'Thu, 22 Aug 2024 00:54:10 '\n",
      "                                                 'GMT',\n",
      "                                         'x-amzn-requestid': '240888d9-1c5c-4a80-987b-480cd8b9bab9'},\n",
      "                        'HTTPStatusCode': 200,\n",
      "                        'RequestId': '240888d9-1c5c-4a80-987b-480cd8b9bab9',\n",
      "                        'RetryAttempts': 0},\n",
      "  'createCollectionDetail': { 'arn': 'arn:aws:aoss:us-east-1:381491840841:collection/x24qujh1lmt7yh6ha6pb',\n",
      "                              'createdDate': 1724288050518,\n",
      "                              'id': 'x24qujh1lmt7yh6ha6pb',\n",
      "                              'kmsKeyArn': 'auto',\n",
      "                              'lastModifiedDate': 1724288050518,\n",
      "                              'name': 'bedrock-sample-rag-414',\n",
      "                              'standbyReplicas': 'ENABLED',\n",
      "                              'status': 'CREATING',\n",
      "                              'type': 'VECTORSEARCH'}}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(collection)\n",
    "time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x24qujh1lmt7yh6ha6pb.us-east-1.aoss.amazonaws.com\n"
     ]
    }
   ],
   "source": [
    "collection_id = collection[\"createCollectionDetail\"][\"id\"]\n",
    "host = collection_id + \".\" + region_name + \".aoss.amazonaws.com\"\n",
    "print(host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opensearch serverless arn:  arn:aws:iam::381491840841:policy/AmazonBedrockOSSPolicyForKnowledgeBase_688\n"
     ]
    }
   ],
   "source": [
    "# Cria a política oss e atacha isso na role de execução do Amazon Bedrock\n",
    "create_oss_policy_attach_bedrock_execution_role(collection_id=collection_id,\n",
    "                                                bedrock_kb_execution_role=bedrock_kb_execution_role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo 2 - Cria o vector index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "credentials = boto3_session.get_credentials()\n",
    "awsauth = auth = AWSV4SignerAuth(credentials, region_name, \"aoss\")\n",
    "\n",
    "index_name = f\"bedrock-sample-index-{suffix}\"\n",
    "body_json = {\n",
    "   \"settings\": {\n",
    "      \"index.knn\": \"true\"\n",
    "   },\n",
    "   \"mappings\": {\n",
    "      \"properties\": {\n",
    "         \"vector\": {\n",
    "            \"type\": \"FAISS\",\n",
    "            \"dimension\": 1536\n",
    "         },\n",
    "         \"text\": {\n",
    "            \"type\": \"text\"\n",
    "         },\n",
    "         \"text-metadata\": {\n",
    "            \"type\": \"text\"         }\n",
    "      }\n",
    "   }\n",
    "}\n",
    "\n",
    "oss_client = OpenSearch(\n",
    "    hosts=[{\"host\": host, \"port\": 443}],\n",
    "    http_auth=awsauth,\n",
    "    use_ssl=True,\n",
    "    verify_certs=True,\n",
    "    connection_class=RequestsHttpConnection,\n",
    "    timeout=300\n",
    ")\n",
    "\n",
    "## Pode levar até um minuto para que as regras de acesso aos dados sejam aplicadas\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RequestError",
     "evalue": "RequestError(400, 'mapper_parsing_exception', 'OpenSearch exception [type=mapper_parsing_exception, reason=No handler for type [FAISS] declared on field [vector]]- server : [envoy]')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRequestError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cria o índice\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m response \u001b[38;5;241m=\u001b[39m oss_client\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mcreate(index\u001b[38;5;241m=\u001b[39mindex_name, body\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(body_json))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCriando o índice:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[1;32mc:\\Users\\CristianoSancho\\anaconda3\\Lib\\site-packages\\opensearchpy\\client\\utils.py:179\u001b[0m, in \u001b[0;36mquery_params.<locals>._wrapper.<locals>._wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m             params[p] \u001b[38;5;241m=\u001b[39m _escape(v)\n\u001b[1;32m--> 179\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, params\u001b[38;5;241m=\u001b[39mparams, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\CristianoSancho\\anaconda3\\Lib\\site-packages\\opensearchpy\\client\\indices.py:128\u001b[0m, in \u001b[0;36mIndicesClient.create\u001b[1;34m(self, index, body, params, headers)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m SKIP_IN_PATH:\n\u001b[0;32m    126\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty value passed for a required argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransport\u001b[38;5;241m.\u001b[39mperform_request(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m, _make_path(index), params\u001b[38;5;241m=\u001b[39mparams, headers\u001b[38;5;241m=\u001b[39mheaders, body\u001b[38;5;241m=\u001b[39mbody\n\u001b[0;32m    130\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\CristianoSancho\\anaconda3\\Lib\\site-packages\\opensearchpy\\transport.py:409\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[1;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 409\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;66;03m# connection didn't fail, confirm it's live status\u001b[39;00m\n\u001b[0;32m    413\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection_pool\u001b[38;5;241m.\u001b[39mmark_live(connection)\n",
      "File \u001b[1;32mc:\\Users\\CristianoSancho\\anaconda3\\Lib\\site-packages\\opensearchpy\\transport.py:370\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[1;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[0;32m    367\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_connection()\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 370\u001b[0m     status, headers_response, data \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mperform_request(\n\u001b[0;32m    371\u001b[0m         method,\n\u001b[0;32m    372\u001b[0m         url,\n\u001b[0;32m    373\u001b[0m         params,\n\u001b[0;32m    374\u001b[0m         body,\n\u001b[0;32m    375\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m    376\u001b[0m         ignore\u001b[38;5;241m=\u001b[39mignore,\n\u001b[0;32m    377\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    378\u001b[0m     )\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;66;03m# Lowercase all the header names for consistency in accessing them.\u001b[39;00m\n\u001b[0;32m    381\u001b[0m     headers_response \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    382\u001b[0m         header\u001b[38;5;241m.\u001b[39mlower(): value \u001b[38;5;28;01mfor\u001b[39;00m header, value \u001b[38;5;129;01min\u001b[39;00m headers_response\u001b[38;5;241m.\u001b[39mitems()\n\u001b[0;32m    383\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\CristianoSancho\\anaconda3\\Lib\\site-packages\\opensearchpy\\connection\\http_requests.py:230\u001b[0m, in \u001b[0;36mRequestsHttpConnection.perform_request\u001b[1;34m(self, method, url, params, body, timeout, allow_redirects, ignore, headers)\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m)\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ignore\n\u001b[0;32m    220\u001b[0m ):\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_request_fail(\n\u001b[0;32m    222\u001b[0m         method,\n\u001b[0;32m    223\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    228\u001b[0m         raw_data,\n\u001b[0;32m    229\u001b[0m     )\n\u001b[1;32m--> 230\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_error(\n\u001b[0;32m    231\u001b[0m         response\u001b[38;5;241m.\u001b[39mstatus_code,\n\u001b[0;32m    232\u001b[0m         raw_data,\n\u001b[0;32m    233\u001b[0m         response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    234\u001b[0m     )\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_request_success(\n\u001b[0;32m    237\u001b[0m     method,\n\u001b[0;32m    238\u001b[0m     url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    243\u001b[0m     duration,\n\u001b[0;32m    244\u001b[0m )\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m.\u001b[39mheaders, raw_data\n",
      "File \u001b[1;32mc:\\Users\\CristianoSancho\\anaconda3\\Lib\\site-packages\\opensearchpy\\connection\\base.py:301\u001b[0m, in \u001b[0;36mConnection._raise_error\u001b[1;34m(self, status_code, raw_data, content_type)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    299\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUndecodable raw error response from server: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, err)\n\u001b[1;32m--> 301\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[38;5;241m.\u001b[39mget(status_code, TransportError)(\n\u001b[0;32m    302\u001b[0m     status_code, error_message, additional_info\n\u001b[0;32m    303\u001b[0m )\n",
      "\u001b[1;31mRequestError\u001b[0m: RequestError(400, 'mapper_parsing_exception', 'OpenSearch exception [type=mapper_parsing_exception, reason=No handler for type [FAISS] declared on field [vector]]- server : [envoy]')"
     ]
    }
   ],
   "source": [
    "# Cria o índice\n",
    "# Tive que alterar o tipo de VECTOR para FAISS, então crie manualmente o Index.\n",
    "response = oss_client.indices.create(index=index_name, body=json.dumps(body_json))\n",
    "print(\"\\nCriando o índice:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "J� existe uma subpasta ou um arquivo data.\n",
      "Erro ao processar: data.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\\\data\\\\AMZN-2022-Shareholder-Letter.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, url \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(urls):\n\u001b[0;32m     20\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m data_directory \u001b[38;5;241m+\u001b[39m filenames[idx]\n\u001b[1;32m---> 21\u001b[0m     urlretrieve(url, file_path)\n",
      "File \u001b[1;32mc:\\Users\\CristianoSancho\\anaconda3\\Lib\\urllib\\request.py:251\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# Handle temporary file setup.\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m--> 251\u001b[0m     tfp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(filename, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    253\u001b[0m     tfp \u001b[38;5;241m=\u001b[39m tempfile\u001b[38;5;241m.\u001b[39mNamedTemporaryFile(delete\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\\\\data\\\\AMZN-2022-Shareholder-Letter.pdf'"
     ]
    }
   ],
   "source": [
    "!mkdir -p data\n",
    "\n",
    "urls = [\n",
    "    \"https://s2.q4cdn.com/299287126/files/doc_financials/2023/ar/2022-Shareholder-Letter.pdf\",\n",
    "    \"https://s2.q4cdn.com/299287126/files/doc_financials/2022/ar/2021-Shareholder-Letter.pdf\",\n",
    "    \"https://s2.q4cdn.com/299287126/files/doc_financials/2021/ar/Amazon-2020-Shareholder-Letter-and-1997-Shareholder-Letter.pdf\",\n",
    "    \"https://s2.q4cdn.com/299287126/files/doc_financials/2020/ar/2019-Shareholder-Letter.pdf\"\n",
    "]\n",
    "\n",
    "filenames = [\n",
    "    \"AMZN-2022-Shareholder-Letter.pdf\",\n",
    "    \"AMZN-2021-Shareholder-Letter.pdf\",\n",
    "    \"AMZN-2020-Shareholder-Letter.pdf\",\n",
    "    \"AMZN-2019-Shareholder-Letter.pdf\"\n",
    "]\n",
    "\n",
    "data_directory = \"\\\\data\\\\\"\n",
    "\n",
    "for idx, url in enumerate(urls):\n",
    "    file_path = data_directory + filenames[idx]\n",
    "    urlretrieve(url, file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sobe os dados no bucket do S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_directory(path,bucket_name):\n",
    "        for root,dirs,files in os.walk(path):\n",
    "            for file in files:\n",
    "                s3_client.upload_file(os.path.join(root,file),bucket_name,file)\n",
    "\n",
    "upload_directory(data_directory, bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar a base de conhecimento\n",
    "Passos:\n",
    "- Inicialize a configuração do OpenSearch serverless, que incluirá o ARN da coleção.\n",
    "- Inicialize a estratégia de divisão em chunks, com base na qual o KB dividirá os documentos em pedaços do tamanho igual ao tamanho de chunk mencionado em `chunkingStrategyConfiguration`.\n",
    "- Inicialize a configuração do S3, que será usada para criar o objeto de fonte de dados posteriormente.\n",
    "- Inicialize o ARN do modelo de embeddings Titan, pois este será usado para criar os embeddings para cada um dos chunks de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "opensearchServerlessConfiguration = {\n",
    "            \"collectionArn\": collection[\"createCollectionDetail\"][\"arn\"],\n",
    "            \"vectorIndexName\": index_name,\n",
    "            \"fieldMapping\": {\n",
    "                \"vectorField\": \"vector\",\n",
    "                \"textField\": \"text\",\n",
    "                \"metadataField\": \"text-metadata\"\n",
    "            }\n",
    "        }\n",
    "\n",
    "chunkingStrategyConfiguration = {\n",
    "    \"chunkingStrategy\": \"FIXED_SIZE\",\n",
    "    \"fixedSizeChunkingConfiguration\": {\n",
    "        \"maxTokens\": 512,\n",
    "        \"overlapPercentage\": 20\n",
    "    }\n",
    "}\n",
    "\n",
    "s3Configuration = {\n",
    "    \"bucketArn\": f\"arn:aws:s3:::{bucket_name}\",\n",
    "}\n",
    "\n",
    "embeddingModelArn = f\"arn:aws:bedrock:{region_name}::foundation-model/amazon.titan-embed-text-v1\"\n",
    "\n",
    "name = f\"bedrock-sample-knowledge-base-{suffix}\"\n",
    "description = \"Amazon shareholder letter knowledge base.\"\n",
    "roleArn = bedrock_kb_execution_role_arn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forneça as configurações acima como entrada para o método `create_knowledge_base`, que criará a base de conhecimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cria a base de conhecimento\n",
    "@retry(wait_random_min=1000, wait_random_max=2000,stop_max_attempt_number=7)\n",
    "def create_knowledge_base():\n",
    "    create_kb_response = bedrock_agent_client.create_knowledge_base(\n",
    "        name = name,\n",
    "        description = description,\n",
    "        roleArn = roleArn,\n",
    "        knowledgeBaseConfiguration = {\n",
    "            \"type\": \"VECTOR\",\n",
    "            \"vectorKnowledgeBaseConfiguration\": {\n",
    "                \"embeddingModelArn\": embeddingModelArn\n",
    "            }\n",
    "        },\n",
    "        storageConfiguration = {\n",
    "            \"type\": \"OPENSEARCH_SERVERLESS\",\n",
    "            \"opensearchServerlessConfiguration\":opensearchServerlessConfiguration\n",
    "        }\n",
    "    )\n",
    "    return create_kb_response[\"knowledgeBase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    kb = create_knowledge_base()\n",
    "except Exception as err:\n",
    "    print(f\"{err=}, {type(err)=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'createdAt': datetime.datetime(2024, 8, 22, 1, 59, 47, 515624, tzinfo=tzutc()),\n",
      "  'description': 'Amazon shareholder letter knowledge base.',\n",
      "  'knowledgeBaseArn': 'arn:aws:bedrock:us-east-1:381491840841:knowledge-base/XRRUN1PPJ0',\n",
      "  'knowledgeBaseConfiguration': { 'type': 'VECTOR',\n",
      "                                  'vectorKnowledgeBaseConfiguration': { 'embeddingModelArn': 'arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1'}},\n",
      "  'knowledgeBaseId': 'XRRUN1PPJ0',\n",
      "  'name': 'bedrock-sample-knowledge-base-414',\n",
      "  'roleArn': 'arn:aws:iam::381491840841:role/AmazonBedrockExecutionRoleForKnowledgeBase_688',\n",
      "  'status': 'CREATING',\n",
      "  'storageConfiguration': { 'opensearchServerlessConfiguration': { 'collectionArn': 'arn:aws:aoss:us-east-1:381491840841:collection/x24qujh1lmt7yh6ha6pb',\n",
      "                                                                   'fieldMapping': { 'metadataField': 'text-metadata',\n",
      "                                                                                     'textField': 'text',\n",
      "                                                                                     'vectorField': 'vector'},\n",
      "                                                                   'vectorIndexName': 'bedrock-sample-index-414'},\n",
      "                            'type': 'OPENSEARCH_SERVERLESS'},\n",
      "  'updatedAt': datetime.datetime(2024, 8, 22, 1, 59, 47, 515624, tzinfo=tzutc())}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recupera a Knowledge Base\n",
    "get_kb_response = bedrock_agent_client.get_knowledge_base(knowledgeBaseId = kb[\"knowledgeBaseId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora precisamos criar uma fonte de dados, que será associada à base de conhecimento criada acima. Assim que a fonte de dados estiver pronta, poderemos começar a ingerir os documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'createdAt': datetime.datetime(2024, 8, 22, 2, 0, 7, 503494, tzinfo=tzutc()),\n",
      "  'dataSourceConfiguration': { 's3Configuration': { 'bucketArn': 'arn:aws:s3:::cdbes01e08-sancho'},\n",
      "                               'type': 'S3'},\n",
      "  'dataSourceId': '2JEBE7LOJP',\n",
      "  'description': 'Amazon shareholder letter knowledge base.',\n",
      "  'knowledgeBaseId': 'XRRUN1PPJ0',\n",
      "  'name': 'bedrock-sample-knowledge-base-414',\n",
      "  'status': 'AVAILABLE',\n",
      "  'updatedAt': datetime.datetime(2024, 8, 22, 2, 0, 7, 503494, tzinfo=tzutc()),\n",
      "  'vectorIngestionConfiguration': { 'chunkingConfiguration': { 'chunkingStrategy': 'FIXED_SIZE',\n",
      "                                                               'fixedSizeChunkingConfiguration': { 'maxTokens': 512,\n",
      "                                                                                                   'overlapPercentage': 20}}}}\n"
     ]
    }
   ],
   "source": [
    "# Cria a fonte de dados na base de conhecimento\n",
    "create_ds_response = bedrock_agent_client.create_data_source(\n",
    "    name = name,\n",
    "    description = description,\n",
    "    knowledgeBaseId = kb[\"knowledgeBaseId\"],\n",
    "    dataSourceConfiguration = {\n",
    "        \"type\": \"S3\",\n",
    "        \"s3Configuration\":s3Configuration\n",
    "    },\n",
    "    vectorIngestionConfiguration = {\n",
    "        \"chunkingConfiguration\": chunkingStrategyConfiguration\n",
    "    }\n",
    ")\n",
    "ds = create_ds_response[\"dataSource\"]\n",
    "pp.pprint(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '47fd0050-5d9a-4fdd-be5b-f33b36a29f23',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Thu, 22 Aug 2024 02:00:14 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '587',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': '47fd0050-5d9a-4fdd-be5b-f33b36a29f23',\n",
       "   'x-amz-apigw-id': 'c41DXF2kIAMEhIA=',\n",
       "   'x-amzn-trace-id': 'Root=1-66c69bae-22de823f1216664e66c498b5'},\n",
       "  'RetryAttempts': 0},\n",
       " 'dataSource': {'knowledgeBaseId': 'XRRUN1PPJ0',\n",
       "  'dataSourceId': '2JEBE7LOJP',\n",
       "  'name': 'bedrock-sample-knowledge-base-414',\n",
       "  'status': 'AVAILABLE',\n",
       "  'description': 'Amazon shareholder letter knowledge base.',\n",
       "  'dataSourceConfiguration': {'type': 'S3',\n",
       "   's3Configuration': {'bucketArn': 'arn:aws:s3:::cdbes01e08-sancho'}},\n",
       "  'vectorIngestionConfiguration': {'chunkingConfiguration': {'chunkingStrategy': 'FIXED_SIZE',\n",
       "    'fixedSizeChunkingConfiguration': {'maxTokens': 512,\n",
       "     'overlapPercentage': 20}}},\n",
       "  'createdAt': datetime.datetime(2024, 8, 22, 2, 0, 7, 503494, tzinfo=tzutc()),\n",
       "  'updatedAt': datetime.datetime(2024, 8, 22, 2, 0, 7, 503494, tzinfo=tzutc())}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recupera a fonte de dados\n",
    "bedrock_agent_client.get_data_source(knowledgeBaseId = kb[\"knowledgeBaseId\"], dataSourceId = ds[\"dataSourceId\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicia o JOB de ingestão\n",
    "Assim que a base de conhecimento e a fonte de dados forem criadas, podemos iniciar o job de ingestão.\n",
    "\n",
    "Durante o job de ingestão, a base de conhecimento buscará os documentos na fonte de dados, pré-processará para extrair o texto, dividirá em chunks com base no tamanho de chunk fornecido, criará embeddings para cada chunk e então gravará no banco de dados vetorial, neste caso o Amazon OpenSearch Serverless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Inicia o job de ingestão\n",
    "start_job_response = bedrock_agent_client.start_ingestion_job(knowledgeBaseId = kb[\"knowledgeBaseId\"], \n",
    "                                                              dataSourceId = ds[\"dataSourceId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job = start_job_response[\"ingestionJob\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'dataSourceId': '2JEBE7LOJP',\n",
      "  'ingestionJobId': 'ZRUVVYJMGV',\n",
      "  'knowledgeBaseId': 'XRRUN1PPJ0',\n",
      "  'startedAt': datetime.datetime(2024, 8, 22, 2, 0, 21, 669046, tzinfo=tzutc()),\n",
      "  'statistics': { 'numberOfDocumentsDeleted': 0,\n",
      "                  'numberOfDocumentsFailed': 0,\n",
      "                  'numberOfDocumentsScanned': 0,\n",
      "                  'numberOfModifiedDocumentsIndexed': 0,\n",
      "                  'numberOfNewDocumentsIndexed': 0},\n",
      "  'status': 'STARTING',\n",
      "  'updatedAt': datetime.datetime(2024, 8, 22, 2, 0, 21, 669046, tzinfo=tzutc())}\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ 'dataSourceId': '2JEBE7LOJP',\n",
      "  'ingestionJobId': 'ZRUVVYJMGV',\n",
      "  'knowledgeBaseId': 'XRRUN1PPJ0',\n",
      "  'startedAt': datetime.datetime(2024, 8, 22, 2, 0, 21, 669046, tzinfo=tzutc()),\n",
      "  'statistics': { 'numberOfDocumentsDeleted': 0,\n",
      "                  'numberOfDocumentsFailed': 0,\n",
      "                  'numberOfDocumentsScanned': 4,\n",
      "                  'numberOfModifiedDocumentsIndexed': 0,\n",
      "                  'numberOfNewDocumentsIndexed': 4},\n",
      "  'status': 'COMPLETE',\n",
      "  'updatedAt': datetime.datetime(2024, 8, 22, 2, 0, 38, 77570, tzinfo=tzutc())}\n"
     ]
    }
   ],
   "source": [
    "# Recupera o job job e aguarda seu término \n",
    "while(job[\"status\"]!=\"COMPLETE\" ):\n",
    "  get_job_response = bedrock_agent_client.get_ingestion_job(\n",
    "      knowledgeBaseId = kb[\"knowledgeBaseId\"],\n",
    "        dataSourceId = ds[\"dataSourceId\"],\n",
    "        ingestionJobId = job[\"ingestionJobId\"]\n",
    "  )\n",
    "  job = get_job_response[\"ingestionJob\"]\n",
    "pp.pprint(job)\n",
    "time.sleep(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'XRRUN1PPJ0'\n"
     ]
    }
   ],
   "source": [
    "kb_id = kb[\"knowledgeBaseId\"]\n",
    "pp.pprint(kb_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando a base de conhecimento\n",
    "### Usando a API RetrieveAndGenerate\n",
    "Por baixo do capô, a API RetrieveAndGenerate converte consultas em embeddings, pesquisa a base de conhecimento e então enriquece o prompt do modelo fundacional com os resultados da pesquisa como informações de contexto e retorna a resposta gerada pelo FM à pergunta. Para conversas com múltiplos turnos, o KB gerencia a memória de curto prazo da conversa para fornecer resultados mais contextuais.\n",
    "\n",
    "A saída da API RetrieveAndGenerate inclui a resposta gerada, atribuição da fonte, bem como os chunks de texto recuperados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# utilizando a Knowledge Base utilizando a API RetrieveAndGenerate\n",
    "bedrock_agent_runtime_client = boto3.client(\"bedrock-agent-runtime\", region_name=region_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Amazon has been working on developing its own large language models (LLMs) '\n",
      " 'for a while. The company believes LLMs and generative AI will transform and '\n",
      " 'improve customer experiences across its consumer, seller, brand, and creator '\n",
      " 'platforms. Additionally, Amazon is making LLMs more accessible through AWS '\n",
      " 'by offering machine learning chips like Trainium and Inferentia to help '\n",
      " 'companies of all sizes train and run their models cost-effectively.')\n"
     ]
    }
   ],
   "source": [
    "response = bedrock_agent_runtime_client.retrieve_and_generate(\n",
    "    input={\n",
    "        \"text\": query\n",
    "    },\n",
    "    retrieveAndGenerateConfiguration={\n",
    "        \"type\": \"KNOWLEDGE_BASE\",\n",
    "        \"knowledgeBaseConfiguration\": {\n",
    "            \"knowledgeBaseId\": kb_id,\n",
    "            \"modelArn\": model_arn\n",
    "        }\n",
    "    },\n",
    ")\n",
    "\n",
    "generated_text = response[\"output\"][\"text\"]\n",
    "pp.pprint(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 'Amazon has been using machine learning extensively for 25 years, employing '\n",
      "  'it in everything from personalized ecommerce recommendations, to '\n",
      "  'fulfillment center pick paths, to drones for Prime Air, to Alexa, to the '\n",
      "  'many machine learning services AWS offers (where AWS has the broadest '\n",
      "  'machine learning functionality and customer base of any cloud provider). '\n",
      "  'More recently, a newer form of machine learning, called Generative AI, has '\n",
      "  'burst onto the scene and promises to significantly accelerate machine '\n",
      "  'learning adoption. Generative AI is based on very Large Language Models '\n",
      "  '(trained on up to hundreds of billions of parameters, and growing), across '\n",
      "  'expansive datasets, and has radically general and broad recall and learning '\n",
      "  'capabilities. We have been working on our own LLMs for a while now, believe '\n",
      "  'it will transform and improve virtually every customer experience, and will '\n",
      "  'continue to invest substantially in these models across all of our '\n",
      "  'consumer, seller, brand, and creator experiences. Additionally, as we’ve '\n",
      "  'done for years in AWS, we’re democratizing this technology so companies of '\n",
      "  'all sizes can leverage Generative AI. AWS is offering the most '\n",
      "  'price-performant machine learning chips in Trainium and Inferentia so small '\n",
      "  'and large companies can afford to train and run their LLMs in production. '\n",
      "  'We enable companies to choose from various LLMs and build applications with '\n",
      "  'all of the AWS security, privacy and other features that customers are '\n",
      "  'accustomed to using. And, we’re delivering applications like AWS’s '\n",
      "  'CodeWhisperer, which revolutionizes        developer productivity by '\n",
      "  'generating code suggestions in real time. I could write an entire letter on '\n",
      "  'LLMs and Generative AI as I think they will be that transformative, but '\n",
      "  'I’ll leave that for a future letter. Let’s just say that LLMs and '\n",
      "  'Generative AI are going to be a big deal for customers, our shareholders, '\n",
      "  'and Amazon.   So, in closing, I’m optimistic that we’ll emerge from this '\n",
      "  'challenging macroeconomic time in a stronger position than when we entered '\n",
      "  'it. There are several reasons for it and I’ve mentioned many of them above. '\n",
      "  'But, there are two relatively simple statistics that underline our immense '\n",
      "  'future opportunity. While we have a consumer business that’s $434B in 2022, '\n",
      "  'the vast majority of total market segment share in global retail still '\n",
      "  'resides in physical stores (roughly 80%). And, it’s a similar story for '\n",
      "  'Global IT spending, where we have AWS revenue of $80B in 2022, with about '\n",
      "  '90% of Global IT spending still on-premises and yet to migrate to the '\n",
      "  'cloud.',\n",
      "  'Amazon has been using machine learning extensively for 25 years, employing '\n",
      "  'it in everything from personalized ecommerce recommendations, to '\n",
      "  'fulfillment center pick paths, to drones for Prime Air, to Alexa, to the '\n",
      "  'many machine learning services AWS offers (where AWS has the broadest '\n",
      "  'machine learning functionality and customer base of any cloud provider). '\n",
      "  'More recently, a newer form of machine learning, called Generative AI, has '\n",
      "  'burst onto the scene and promises to significantly accelerate machine '\n",
      "  'learning adoption. Generative AI is based on very Large Language Models '\n",
      "  '(trained on up to hundreds of billions of parameters, and growing), across '\n",
      "  'expansive datasets, and has radically general and broad recall and learning '\n",
      "  'capabilities. We have been working on our own LLMs for a while now, believe '\n",
      "  'it will transform and improve virtually every customer experience, and will '\n",
      "  'continue to invest substantially in these models across all of our '\n",
      "  'consumer, seller, brand, and creator experiences. Additionally, as we’ve '\n",
      "  'done for years in AWS, we’re democratizing this technology so companies of '\n",
      "  'all sizes can leverage Generative AI. AWS is offering the most '\n",
      "  'price-performant machine learning chips in Trainium and Inferentia so small '\n",
      "  'and large companies can afford to train and run their LLMs in production. '\n",
      "  'We enable companies to choose from various LLMs and build applications with '\n",
      "  'all of the AWS security, privacy and other features that customers are '\n",
      "  'accustomed to using. And, we’re delivering applications like AWS’s '\n",
      "  'CodeWhisperer, which revolutionizes        developer productivity by '\n",
      "  'generating code suggestions in real time. I could write an entire letter on '\n",
      "  'LLMs and Generative AI as I think they will be that transformative, but '\n",
      "  'I’ll leave that for a future letter. Let’s just say that LLMs and '\n",
      "  'Generative AI are going to be a big deal for customers, our shareholders, '\n",
      "  'and Amazon.   So, in closing, I’m optimistic that we’ll emerge from this '\n",
      "  'challenging macroeconomic time in a stronger position than when we entered '\n",
      "  'it. There are several reasons for it and I’ve mentioned many of them above. '\n",
      "  'But, there are two relatively simple statistics that underline our immense '\n",
      "  'future opportunity. While we have a consumer business that’s $434B in 2022, '\n",
      "  'the vast majority of total market segment share in global retail still '\n",
      "  'resides in physical stores (roughly 80%). And, it’s a similar story for '\n",
      "  'Global IT spending, where we have AWS revenue of $80B in 2022, with about '\n",
      "  '90% of Global IT spending still on-premises and yet to migrate to the '\n",
      "  'cloud.']\n"
     ]
    }
   ],
   "source": [
    "## Imprime a atribuição da fonte/citações dos documentos originais para ver se a resposta gerada pertence ao contexto.\n",
    "citations = response[\"citations\"]\n",
    "contexts = []\n",
    "for citation in citations:\n",
    "    retrievedReferences = citation[\"retrievedReferences\"]\n",
    "    for reference in retrievedReferences:\n",
    "        contexts.append(reference[\"content\"][\"text\"])\n",
    "\n",
    "pp.pprint(contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve API\n",
    "A API Retrieve converte consultas de usuários em embeddings, pesquisa a base de conhecimento e retorna os resultados relevantes, dando a você mais controle para construir fluxos de trabalho personalizados com base nos resultados da pesquisa semântica.\n",
    "\n",
    "A saída da API Retrieve inclui os chunks de texto recuperados, o tipo de localização e URI dos dados de origem, bem como as pontuações de relevância das recuperações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# API de recuperação para buscar apenas o contexto relevante.\n",
    "relevant_documents = bedrock_agent_runtime_client.retrieve(\n",
    "    retrievalQuery= {\n",
    "        \"text\": query\n",
    "    },\n",
    "    knowledgeBaseId=kb_id,\n",
    "    retrievalConfiguration= {\n",
    "        \"vectorSearchConfiguration\": {\n",
    "            \"numberOfResults\": 3 #  irá recuperar os 3 principais documentos que correspondem à consulta.\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ { 'content': { 'text': 'Amazon has been using machine learning extensively '\n",
      "                         'for 25 years, employing it in everything from '\n",
      "                         'personalized ecommerce recommendations, to '\n",
      "                         'fulfillment center pick paths, to drones for Prime '\n",
      "                         'Air, to Alexa, to the many machine learning services '\n",
      "                         'AWS offers (where AWS has the broadest machine '\n",
      "                         'learning functionality and customer base of any '\n",
      "                         'cloud provider). More recently, a newer form of '\n",
      "                         'machine learning, called Generative AI, has burst '\n",
      "                         'onto the scene and promises to significantly '\n",
      "                         'accelerate machine learning adoption. Generative AI '\n",
      "                         'is based on very Large Language Models (trained on '\n",
      "                         'up to hundreds of billions of parameters, and '\n",
      "                         'growing), across expansive datasets, and has '\n",
      "                         'radically general and broad recall and learning '\n",
      "                         'capabilities. We have been working on our own LLMs '\n",
      "                         'for a while now, believe it will transform and '\n",
      "                         'improve virtually every customer experience, and '\n",
      "                         'will continue to invest substantially in these '\n",
      "                         'models across all of our consumer, seller, brand, '\n",
      "                         'and creator experiences. Additionally, as we’ve done '\n",
      "                         'for years in AWS, we’re democratizing this '\n",
      "                         'technology so companies of all sizes can leverage '\n",
      "                         'Generative AI. AWS is offering the most '\n",
      "                         'price-performant machine learning chips in Trainium '\n",
      "                         'and Inferentia so small and large companies can '\n",
      "                         'afford to train and run their LLMs in production. We '\n",
      "                         'enable companies to choose from various LLMs and '\n",
      "                         'build applications with all of the AWS security, '\n",
      "                         'privacy and other features that customers are '\n",
      "                         'accustomed to using. And, we’re delivering '\n",
      "                         'applications like AWS’s CodeWhisperer, which '\n",
      "                         'revolutionizes        developer productivity by '\n",
      "                         'generating code suggestions in real time. I could '\n",
      "                         'write an entire letter on LLMs and Generative AI as '\n",
      "                         'I think they will be that transformative, but I’ll '\n",
      "                         'leave that for a future letter. Let’s just say that '\n",
      "                         'LLMs and Generative AI are going to be a big deal '\n",
      "                         'for customers, our shareholders, and Amazon.   So, '\n",
      "                         'in closing, I’m optimistic that we’ll emerge from '\n",
      "                         'this challenging macroeconomic time in a stronger '\n",
      "                         'position than when we entered it. There are several '\n",
      "                         'reasons for it and I’ve mentioned many of them '\n",
      "                         'above. But, there are two relatively simple '\n",
      "                         'statistics that underline our immense future '\n",
      "                         'opportunity. While we have a consumer business '\n",
      "                         'that’s $434B in 2022, the vast majority of total '\n",
      "                         'market segment share in global retail still resides '\n",
      "                         'in physical stores (roughly 80%). And, it’s a '\n",
      "                         'similar story for Global IT spending, where we have '\n",
      "                         'AWS revenue of $80B in 2022, with about 90% of '\n",
      "                         'Global IT spending still on-premises and yet to '\n",
      "                         'migrate to the cloud.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://cdbes01e08-sancho/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'score': 0.6664225},\n",
      "  { 'content': { 'text': 'Our Inferentia2 chip, which just launched, offers up '\n",
      "                         'to four times higher throughput and ten times lower '\n",
      "                         'latency than our first Inferentia processor. With '\n",
      "                         'the enormous upcoming growth in machine learning, '\n",
      "                         'customers will be able to get a lot more done with '\n",
      "                         'AWS’s training and inference chips at a '\n",
      "                         'significantly lower cost. We’re not close to being '\n",
      "                         'done innovating here, and this long-term investment '\n",
      "                         'should prove fruitful for both customers and AWS. '\n",
      "                         'AWS is still in the early stages of its evolution, '\n",
      "                         'and has a chance for unusual growth in the next '\n",
      "                         'decade.   Similarly high potential, Amazon’s '\n",
      "                         'Advertising business is uniquely effective for '\n",
      "                         'brands, which is part of why it continues to grow at '\n",
      "                         'a brisk clip. Akin to physical retailers’ '\n",
      "                         'advertising businesses selling shelf space, end- '\n",
      "                         'caps, and placement in their circulars, our '\n",
      "                         'sponsored products and brands offerings have been an '\n",
      "                         'integral part        of the Amazon shopping '\n",
      "                         'experience for more than a decade. However, unlike '\n",
      "                         'physical retailers, Amazon can tailor these '\n",
      "                         'sponsored products to be relevant to what customers '\n",
      "                         'are searching for given what we know about shopping '\n",
      "                         'behaviors and our very deep investment in machine '\n",
      "                         'learning algorithms. This leads to advertising '\n",
      "                         'that’s more useful for customers; and as a result, '\n",
      "                         'performs better for brands. This is part of why our '\n",
      "                         'Advertising revenue has continued to grow rapidly '\n",
      "                         '(23% YoY in Q4 2022, 25% YoY overall for 2022 on a '\n",
      "                         '$31B revenue base), even as most large '\n",
      "                         'advertising-focused businesses’ growth have slowed '\n",
      "                         'over the last several quarters.   We strive to be '\n",
      "                         'the best place for advertisers to build their '\n",
      "                         'brands. We have near and long-term opportunities '\n",
      "                         'that will help us achieve that mission. We’re '\n",
      "                         'continuing to make large investments in machine '\n",
      "                         'learning to keep honing our advertising selection '\n",
      "                         'algorithms. For the past couple of years, we’ve '\n",
      "                         'invested in building comprehensive, flexible, and '\n",
      "                         'durable planning and measurement solutions, giving '\n",
      "                         'marketers greater insight into advertising '\n",
      "                         'effectiveness. An example is Amazon Marketing Cloud '\n",
      "                         '(“AMC”). AMC is a “clean room” (i.e. secure digital '\n",
      "                         'environment) in which advertisers can run custom '\n",
      "                         'audience and campaign analytics across a range of '\n",
      "                         'first and third-party inputs, in a privacy-safe '\n",
      "                         'manner, to generate advertising and business '\n",
      "                         'insights to inform their broader marketing and sales '\n",
      "                         'strategies. The Advertising and AWS teams have '\n",
      "                         'collaborated to enable companies to store their data '\n",
      "                         'in AWS, operate securely in AMC with Amazon and '\n",
      "                         'other third-party data sources, perform analytics in '\n",
      "                         'AWS, and have the option to activate advertising on '\n",
      "                         'Amazon or third-party publishers through the Amazon '\n",
      "                         'Demand-Side Platform.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://cdbes01e08-sancho/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'score': 0.5487171},\n",
      "  { 'content': { 'text': 'Imagine what they’ll be able to do with reliable '\n",
      "                         'connectivity, from people taking online education '\n",
      "                         'courses, using financial services, starting their '\n",
      "                         'own businesses, doing their shopping, enjoying '\n",
      "                         'entertainment, to businesses and governments '\n",
      "                         'improving their coverage, efficiency, and '\n",
      "                         'operations. Kuiper will deliver not only '\n",
      "                         'accessibility, but affordability. Our teams have '\n",
      "                         'developed low-cost antennas (i.e. customer '\n",
      "                         'terminals) that will lower the barriers to access. '\n",
      "                         'We recently unveiled the new terminals that will '\n",
      "                         'communicate with the satellites passing overhead, '\n",
      "                         'and we expect to be able to produce our standard '\n",
      "                         'residential version for less than $400 each. They’re '\n",
      "                         'small: 11 inches square, 1 inch thick, and weigh '\n",
      "                         'less than 5 pounds without their mounting bracket, '\n",
      "                         'but they deliver speeds up to 400 megabits per '\n",
      "                         'second. And they’re powered by Amazon-designed '\n",
      "                         'baseband chips. We’re preparing to launch two '\n",
      "                         'prototype satellites to test the entire end-to-end '\n",
      "                         'communications network this year, and plan to be in '\n",
      "                         'beta with commercial customers in 2024. The customer '\n",
      "                         'reaction to what we’ve shared thus far about Kuiper '\n",
      "                         'has been very positive, and we believe Kuiper '\n",
      "                         'represents a very large potential opportunity for '\n",
      "                         'Amazon. It also shares several similarities to AWS '\n",
      "                         'in that it’s capital intensive at the start, but has '\n",
      "                         'a large prospective consumer, enterprise, and '\n",
      "                         'government customer base, significant revenue and '\n",
      "                         'operating profit potential, and relatively few '\n",
      "                         'companies with the technical and inventive aptitude, '\n",
      "                         'as well as the investment hypothesis to go after '\n",
      "                         'it.   One final investment area that I’ll mention, '\n",
      "                         'that’s core to setting Amazon up to invent in every '\n",
      "                         'area of our business for many decades to come, and '\n",
      "                         'where we’re investing heavily is Large Language '\n",
      "                         'Models (“LLMs”) and Generative AI. Machine learning '\n",
      "                         'has been a technology with high promise for several '\n",
      "                         'decades, but it’s only been the last five to ten '\n",
      "                         'years that it’s started to be used more pervasively '\n",
      "                         'by companies. This shift was driven by several '\n",
      "                         'factors, including access to higher volumes of '\n",
      "                         'compute capacity at lower prices than was ever '\n",
      "                         'available. Amazon has been using machine learning '\n",
      "                         'extensively for 25 years, employing it in everything '\n",
      "                         'from personalized ecommerce recommendations, to '\n",
      "                         'fulfillment center pick paths, to drones for Prime '\n",
      "                         'Air, to Alexa, to the many machine learning services '\n",
      "                         'AWS offers (where AWS has the broadest machine '\n",
      "                         'learning functionality and customer base of any '\n",
      "                         'cloud provider). More recently, a newer form of '\n",
      "                         'machine learning, called Generative AI, has burst '\n",
      "                         'onto the scene and promises to significantly '\n",
      "                         'accelerate machine learning adoption.'},\n",
      "    'location': { 's3Location': { 'uri': 's3://cdbes01e08-sancho/AMZN-2022-Shareholder-Letter.pdf'},\n",
      "                  'type': 'S3'},\n",
      "    'score': 0.53047615}]\n"
     ]
    }
   ],
   "source": [
    "pp.pprint(relevant_documents[\"retrievalResults\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpando a casa\n",
    "Lembre-se de excluir todos os recursos criados, pois você incorrerá em custos para armazenar documentos no índice OSS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'c482d5fc-f23b-4f08-91e5-615bf70dcda5',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'c482d5fc-f23b-4f08-91e5-615bf70dcda5',\n",
       "   'date': 'Thu, 22 Aug 2024 02:57:33 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deleta a base de conhecimento\n",
    "bedrock_agent_client.delete_data_source(dataSourceId = ds[\"dataSourceId\"], knowledgeBaseId=kb[\"knowledgeBaseId\"])\n",
    "bedrock_agent_client.delete_knowledge_base(knowledgeBaseId=kb[\"knowledgeBaseId\"])\n",
    "\n",
    "oss_client.indices.delete(index=index_name)\n",
    "\n",
    "aoss_client.delete_collection(id=collection_id)\n",
    "\n",
    "aoss_client.delete_access_policy(type=\"data\", name=access_policy[\"accessPolicyDetail\"][\"name\"])\n",
    "aoss_client.delete_security_policy(type=\"network\", name=network_policy[\"securityPolicyDetail\"][\"name\"])\n",
    "aoss_client.delete_security_policy(type=\"encryption\", name=encryption_policy[\"securityPolicyDetail\"][\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exclui a role e as políticas\n",
    "from utility import delete_iam_role_and_policies\n",
    "delete_iam_role_and_policies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
